{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras import layers, Model\n",
    "from src.utils import *\n",
    "from src.gcn_model import GraphConvolution, build_gcn_model\n",
    "from src.train_eval import train_and_evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "18e8beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "cites_df = pd.read_csv('./cora/cora.cites', sep='\\t',header=None, names=[\"start\", \"end\"]) \n",
    "content_df = pd.read_csv('./cora/cora.content', sep='\\t', header=None)\n",
    "# The first column is the paper ID, the last is the class label, the rest are the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2e161219",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes with features\n",
    "for _, row in content_df.iterrows():\n",
    "    node_id = row[0]\n",
    "    features = row[1:-1].values\n",
    "    label = row.values[-1]\n",
    "    graph.add_node(node_id, feature=features, label=label)\n",
    "\n",
    "# Add edges from citations\n",
    "for _, row in cites_df.iterrows():\n",
    "    src = row['start']\n",
    "    dst = row['end']\n",
    "    graph.add_edge(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e9f5a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =get_node_labels(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e919482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f2a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjacency matrix\n",
    "adj_matrix = nx.to_numpy_array(graph, nodelist=np.array(list(graph.nodes())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02fbae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(content_df.iloc[:, -1])\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = onehot_encoder.fit_transform(y_encoded.reshape(-1, 1))\n",
    "num_classes = y_onehot.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1e80af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  31336, 1061127, 1106406, ..., 1128978,  117328,   24043])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_ids = content_df.iloc[:, 0].values\n",
    "paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "71598188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Case_Based', 'Genetic_Algorithms', 'Neural_Networks',\n",
       "       'Probabilistic_Methods', 'Reinforcement_Learning', 'Rule_Learning',\n",
       "       'Theory'], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(content_df.iloc[:, -1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0735731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subjects = np.unique(content_df.iloc[:, -1].values)\n",
    "num_nodes = len(paper_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directed graph from the cites data\n",
    "G = nx.from_pandas_edgelist(cites_df, 'start', 'end', create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdbaaff",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a5be0",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c0cf5b",
   "metadata": {},
   "source": [
    "3. Develop a machine learning approach to predict the subjects of papers.\n",
    "4. Train your approach on 9 folds, evaluate it on 1 fold, repeat this process 10 times, and concatenate your predictions such that you have a prediction for every data point in the end.\n",
    "5. Store your predictions in a file as tab-separated values (TSV) in the format <paper_id> <class_label> where class_label is a string.\n",
    "6. Evaluate your approach in terms of accuracy indicating the percentage of nodes that were predicted correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a3bed",
   "metadata": {},
   "source": [
    "1. Create a GitHub repository, grant access to the GitHub user heindorf and send an email with the name of the repository to heindorf@uni-paderborn.de.\n",
    "2. Upload your code (Python preferred) to the repository.\n",
    "3. Upload your predictions (TSV file) to the repository.\n",
    "4. Document your approach in the README file. \\\n",
    "Describe what dependencies are required and how to run your code-ideally with a single command. \\\n",
    "Moreover, briefly explain the core idea of your approach in the README file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
